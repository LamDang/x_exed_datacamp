{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting-kit for ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "We can load the dataset that we cleaned during the first session. We have to take care about parsing date and time columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:17:42.006063Z",
     "start_time": "2019-03-22T15:17:41.621392Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'cleaner_dataframe.csv',\n",
    "    index_col=0,\n",
    "    parse_dates=[\n",
    "        'FE_Declaration_date',\n",
    "        'Claim Incident date',\n",
    "        'Initial coverage date',\n",
    "        'First claim decision date',\n",
    "        'Last claim decisión date',\n",
    "        'Policy Holder date of birth'\n",
    "    ]\n",
    ")\n",
    "df.loc[:, 'Age policy at claim'] = pd.to_timedelta(df.loc[:, 'Age policy at claim'])\n",
    "df.loc[:, 'Delay declaration'] = pd.to_timedelta(df.loc[:, 'Delay declaration'])\n",
    "df.loc[:, 'Age client at claim'] = pd.to_timedelta(df.loc[:, 'Age client at claim'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to be sure that everything was properly parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:17:42.809082Z",
     "start_time": "2019-03-22T15:17:42.765768Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can use the `category` pandas data type for the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:17:50.733566Z",
     "start_time": "2019-03-22T15:17:50.730212Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_int_object(col):\n",
    "    serie = []\n",
    "    for _, x in col.iteritems():\n",
    "        try:\n",
    "            serie.append(int(x))\n",
    "        except ValueError:\n",
    "            serie.append(np.nan)\n",
    "    return pd.Series(serie, index=col.index, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:17:52.731416Z",
     "start_time": "2019-03-22T15:17:52.562704Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Risk code'] = df['Risk code'].astype('category')\n",
    "df['Sexo'] = df['Sexo'].astype('category')\n",
    "df['Refused decision reason code'] = convert_to_int_object(df['Refused decision reason code']).astype('category')\n",
    "df['Trad_Refusal_reason'] = df['Trad_Refusal_reason'].astype('category')\n",
    "df['Refusal_Category'] = df['Refusal_Category'].astype('category')\n",
    "df['Claim_Status_Level_0']= df['Claim_Status_Level_0'].astype('category')\n",
    "df['Refusal_Flag'] = df['Refusal_Flag'].astype('category')\n",
    "df['Local Partner name categories'] = df['Local Partner name categories'].astype('category')\n",
    "df['Insured NIF categories'] = df['Insured NIF categories'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that there is a set of columns that we should not consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T15:17:53.071823Z",
     "start_time": "2019-03-22T15:17:52.997490Z"
    }
   },
   "outputs": [],
   "source": [
    "target = df['Refusal_Flag']\n",
    "data = df.drop(columns=[\n",
    "    'Refusal_Flag',\n",
    "    'Refused decision reason code',\n",
    "    'Claim_Status_Level_0',\n",
    "    'Trad_Refusal_reason',\n",
    "    'Refusal_Category',\n",
    "    'First claim decision date',\n",
    "    'Last claim decisión date',\n",
    "    'Insured NIF categories',\n",
    "    'Claim Number categories'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the `Refusal_Category`, we can check the reason of refusal. We will take a subset of data and reject the \"Admnistrative\" rows for this first try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Refusal_Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_not_administrative = ~(df['Refusal_Category'] == 'Administrative')\n",
    "data = data[mask_not_administrative]\n",
    "target = target[mask_not_administrative]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the different part of the pipeline:\n",
    "\n",
    "* Encode the categorical data;\n",
    "* Drop the date columns;\n",
    "* Let the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "categorical_columns = make_column_selector(dtype_include=\"category\")(data)\n",
    "numerical_columns = make_column_selector(dtype_include=[np.int64, np.float64])(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), categorical_columns),\n",
    "    (\"passthrough\", numerical_columns),\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a RandomForestClassifier to make some classification within a 3-fold cross-validation. We will return the `balanced_accuracy_score` and the `roc_auc_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(preprocessor, RandomForestClassifier(n_estimators=100, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, stratify=target, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that our pipeline is working before to perform the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model, data, label, scoring=['roc_auc', 'balanced_accuracy'], cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the scores to a dataframe to have a nice display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean().to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the std. dev. of those performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.std().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
