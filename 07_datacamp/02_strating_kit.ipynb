{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DataFrame_Claims_Spain.csv', encoding='latin_1', index_col=0,\n",
    "                 parse_dates=['Claim Incident date', 'FE_Declaration_date', 'Initial coverage date',\n",
    "                              'First claim decision date', 'Last claim decisi√≥n date', 'Policy Holder date of birth'],\n",
    "                              infer_datetime_format=True, dtype={'Age at signature': np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `'Policy Holder date of birth'` contain a corrupted date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Policy Holder date of birth'][df['Policy Holder date of birth'].str.contains('1070')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[33949, 'Policy Holder date of birth'] = '19/05/1970'\n",
    "df.loc[33949, 'Age at signature'] = 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the column containing some date to the `datetime` dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Policy Holder date of birth'] = pd.to_datetime(df['Policy Holder date of birth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to category the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int_object(col):\n",
    "    serie = []\n",
    "    for _, x in col.iteritems():\n",
    "        try:\n",
    "            serie.append(int(x))\n",
    "        except ValueError:\n",
    "            serie.append(np.nan)\n",
    "    return pd.Series(serie, index=col.index, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Risk code'] = df['Risk code'].astype('category')\n",
    "df['Sexo'] = df['Sexo'].astype('category')\n",
    "df['Refused decision reason code'] = convert_to_int_object(df['Refused decision reason code']).astype('category')\n",
    "df['Trad_Refusal_reason'] = df['Trad_Refusal_reason'].astype('category')\n",
    "df['Refusal_Category'] = df['Refusal_Category'].astype('category')\n",
    "df['Claim_Status_Level_0']= df['Claim_Status_Level_0'].astype('category')\n",
    "df['Refusal_Flag'] = df['Refusal_Flag'].astype('category')\n",
    "df['Local Partner name categories'] = df['Local Partner name categories'].astype('category')\n",
    "df['Insured NIF categories'] = df['Insured NIF categories'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the column to not consider during classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['Refusal_Flag']\n",
    "data = df.drop(columns=[\n",
    "    'Refusal_Flag',\n",
    "    'Refused decision reason code',\n",
    "    'Claim_Status_Level_0',\n",
    "    'Trad_Refusal_reason',\n",
    "    'Refusal_Category'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label = label_encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the different part of the pipeline:\n",
    "\n",
    "* One-hot encode the categorical features;\n",
    "* Ordinal encode the binary categorical features;\n",
    "* Standard scale the numerical features;\n",
    "* Feature engineer the date by creating: (i) the time to declaration and (ii) the contract seniority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_cat_features = ['Risk code',\n",
    "                                'Local Partner name categories',\n",
    "                                'Insured NIF categories',\n",
    "                                'Claim Number categories']\n",
    "ordinal_encoded_features = ['Sexo']\n",
    "standard_scaled_features = ['Insured amount', 'Initial_Instalment_Amount',\n",
    "                            'Age at signature']\n",
    "time_to_declaration_features = ['FE_Declaration_date', 'Claim Incident date']\n",
    "contract_seniority_features = ['Claim Incident date', 'Initial coverage date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from function_FunctionTransformer import time_to_declaration\n",
    "from function_FunctionTransformer import contract_seniority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (ordinal_encoded_features, OrdinalEncoder()),\n",
    "    (one_hot_encoded_cat_features, make_pipeline(\n",
    "        SimpleImputer(strategy='constant', fill_value=-1),\n",
    "        OneHotEncoder(handle_unknown='ignore'))),\n",
    "    (time_to_declaration_features, make_pipeline(\n",
    "        FunctionTransformer(func=time_to_declaration, validate=False),\n",
    "        MinMaxScaler())),\n",
    "    (contract_seniority_features, make_pipeline(\n",
    "        FunctionTransformer(func=contract_seniority, validate=False),\n",
    "        MinMaxScaler())),\n",
    "    (standard_scaled_features, make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SimpleImputer(strategy='median'))),\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a RandomForestClassifier to make some classification within a 3-fold cross-validation. We will return the `balanced_accuracy_score` and the `roc_auc_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(preprocessor, RandomForestClassifier(n_estimators=100, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(pipe, data, label, scoring=['roc_auc', 'balanced_accuracy'], cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the scores to a dataframe to have a nice display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean().to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the std. dev. of those performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.std().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
